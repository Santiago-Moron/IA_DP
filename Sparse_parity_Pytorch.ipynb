{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/estimator?hl=es-419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PrivacyEngine.__init__() got an unexpected keyword argument 'sample_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), weight_decay\u001b[38;5;241m=\u001b[39ml2_lambda)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Attach Privacy Engine\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m privacy_engine \u001b[38;5;241m=\u001b[39m \u001b[43mPrivacyEngine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43malphas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoise_multiplier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise_multiplier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_grad_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m privacy_engine\u001b[38;5;241m.\u001b[39mattach(optimizer)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: PrivacyEngine.__init__() got an unexpected keyword argument 'sample_size'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Hyperparameters\n",
    "train_size = 900\n",
    "test_size = 1000\n",
    "l2_lambda = 1e-4  # Weight decay\n",
    "noise_multiplier = 1.0  # Noise multiplier for DP\n",
    "max_grad_norm = 1.0  # Clip the gradients\n",
    "\n",
    "# Data generation (parity check on first 3 bits, 30-bit input)\n",
    "unique_binary_strings = set()\n",
    "while len(unique_binary_strings) < train_size + test_size:\n",
    "    binary_string = tuple(np.random.randint(2, size=30))\n",
    "    unique_binary_strings.add(binary_string)\n",
    "\n",
    "inputs = np.array(list(unique_binary_strings), dtype=np.float32)\n",
    "outputs = np.sum(inputs[:, :3], axis=-1) % 2  # Parity check on first 3 bits\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "outputs = torch.tensor(outputs, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Split into train and evaluation sets\n",
    "indices = torch.randperm(len(inputs))\n",
    "split_idx = train_size\n",
    "X_train, y_train = inputs[indices[:split_idx]], outputs[indices[:split_idx]]\n",
    "X_eval, y_eval = inputs[indices[split_idx:]], outputs[indices[split_idx:]]\n",
    "\n",
    "# Define the MLP model with L2 regularization\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(31, 30)  # Input dim + 1 for bias\n",
    "        self.fc2 = nn.Linear(30, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return torch.sigmoid(self.fc2(x))\n",
    "\n",
    "# Instantiate the model, define loss and optimizer\n",
    "model = MLP()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), weight_decay=l2_lambda)\n",
    "\n",
    "# Attach Privacy Engine\n",
    "privacy_engine = PrivacyEngine()\n",
    "model, optimizer, data_loader = privacy_engine.make_private(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=data_loader,\n",
    "    noise_multiplier=1.1,\n",
    "    max_grad_norm=1.0,\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 500\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs_train = model(X_train)\n",
    "    loss = criterion(outputs_train, y_train)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Get train accuracy\n",
    "    with torch.no_grad():\n",
    "        train_accuracy = ((outputs_train > 0.5).float() == y_train).float().mean().item()\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    model.eval()\n",
    "    outputs_eval = model(X_eval)\n",
    "    test_accuracy = ((outputs_eval > 0.5).float() == y_eval).float().mean().item()\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Step the privacy engine\n",
    "    privacy_engine.step()\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Train Acc: {train_accuracy:.4f}, Test Acc: {test_accuracy:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Final Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plot training and test accuracy over epochs\n",
    "plt.plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
